{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "Chris Dailey\n",
    "\n",
    "christopher.dailey@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HW 7.0\n",
    "In this part of your assignment you will develop the base of your code for the week.\n",
    "\n",
    "Write MRJob classes to find shortest path graph distances, \n",
    "as described in the lectures. In addition to finding the distances, \n",
    "your code should also output a distance-minimizing path between the source and target.\n",
    "Work locally for this part of the assignment, and use \n",
    "both of the undirected and directed toy networks.\n",
    "\n",
    "To proof you code's function, run the following jobs\n",
    "\n",
    "- shortest path in the undirected network from node 1 to node 4\n",
    "Solution: 1,5,4 \n",
    "\n",
    "- shortest path in the directed network from node 1 to node 5\n",
    "Solution: 1,2,4,5\n",
    "\n",
    "and report your output---make sure it is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRJobGraph1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRJobGraph1.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re, sys\n",
    "\n",
    "\n",
    "class MRJobPrepGraphData(MRJob):\n",
    "    # run before the mapper processes any input\n",
    "    \n",
    "    def configure_options(self):\n",
    "        super(MRJobPrepGraphData, self).configure_options()\n",
    "        self.add_passthrough_option(\"--startnode\", default=\"1\", type=str)\n",
    "        \n",
    "    def label_dataset(self, _, line):\n",
    "        \n",
    "        source_node_id = int(self.options.startnode)\n",
    "        # Read dataset and add labels and distances\n",
    "        splits = line.split(\"\\t\")\n",
    "        node_id = int(splits[0])\n",
    "        edges = eval(splits[1])\n",
    "        if (node_id == source_node_id):\n",
    "            yield str(node_id), str([int(x) for x in edges.keys()]) + \"|0|[]|Q\"\n",
    "        else:\n",
    "            yield str(node_id), str([int(x) for x in edges.keys()]) + \"|\"+str(sys.maxint)+\"|[]|U\"\n",
    "            \n",
    "    def steps(self):\n",
    "        return [MRStep(mapper=self.label_dataset)]\n",
    "\n",
    "class MRJobGraph1(MRJob):\n",
    "    \n",
    "    def configure_options(self):\n",
    "        super(MRJobGraph1, self).configure_options()\n",
    "        self.add_passthrough_option(\"--endnode\", default=None, type=str)\n",
    "\n",
    "    def push_frontier(self, _, line):\n",
    "        self.increment_counter('states', 'Q', 0)\n",
    "        splits = line.split('\\t')\n",
    "        key = int(splits[0])\n",
    "        value = splits[1]\n",
    "        value_splits = value.split('|')\n",
    "        edges = eval(value_splits[0])\n",
    "        distance = int(value_splits[1])\n",
    "        path = eval(value_splits[2])\n",
    "        status = value_splits[3]\n",
    "        if status == 'Q':\n",
    "            path.append(key)\n",
    "            for edge in edges:\n",
    "                yield int(edge), '[]|'+str(distance + 1) + '|' + str(path) + '|Q'\n",
    "            status = 'V'\n",
    "        if status == 'U' or status == 'V':\n",
    "            yield int(key), str(edges) + '|' + str(distance) + '|' + str(path) + '|' + status\n",
    "    \n",
    "    def combine_records(self, key, values):\n",
    "        self.increment_counter(\"completionstatus\", \"endreached\", 0)\n",
    "        final_edges = []\n",
    "        final_distance = sys.maxint\n",
    "        final_status = '?'\n",
    "        final_path = []\n",
    "        for value in values:\n",
    "            value_splits = value.split('|')\n",
    "            edges = eval(value_splits[0])\n",
    "            distance = int(value_splits[1])\n",
    "            path = eval(value_splits[2])\n",
    "            status = value_splits[3]\n",
    "            final_edges = final_edges + edges\n",
    "            final_distance = min(final_distance, distance)\n",
    "            if final_status == '?' or final_status == 'U':\n",
    "                final_status = status\n",
    "                if status == 'Q':\n",
    "                    self.increment_counter('states', 'Q', 1)\n",
    "                if status == 'Q' or status == 'V':\n",
    "                    final_path = path\n",
    "#             if final_status == 'U' and len(path) > len(final_path):\n",
    "#                 final_path = path\n",
    "        if self.options.endnode != None and int(self.options.endnode) == key and final_status == \"V\":\n",
    "            self.increment_counter(\"completionstatus\", \"endreached\", 1)\n",
    "        yield key, str(final_edges) + '|' + str(final_distance) + '|' +  str(final_path) + '|' + final_status\n",
    "        \n",
    "        \n",
    "    def passthrough(self, key, value):\n",
    "        yield key, value\n",
    "    \n",
    "\n",
    "    \n",
    "    def steps(self):\n",
    "        return [#MRStep(mapper=self.passthrough)\n",
    "                MRStep(mapper=self.push_frontier,\n",
    "                       reducer=self.combine_records)\n",
    "               ]\n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobGraph1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import random,array\n",
    "from MRJobGraph1 import MRJobGraph1, MRJobPrepGraphData\n",
    "\n",
    "def SSSP(filename, source_node, end_node):\n",
    "    prep_data = MRJobPrepGraphData(args=[filename, '--no-strict-protocol', \"--startnode\", source_node])\n",
    "    with prep_data.make_runner() as runner:\n",
    "        prepped_data = open(\"prepped_data0.txt\", 'w')\n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value = prep_data.parse_output_line(line)\n",
    "            print key + \"\\t\" + value\n",
    "            prepped_data.write(key + '\\t' + value + '\\n')\n",
    "        prepped_data.close()\n",
    "\n",
    "\n",
    "    print \"\\n\\nSecond Job:\\n\\n\"\n",
    "\n",
    "    iteration = 1\n",
    "    while(True):\n",
    "        mr_job = MRJobGraph1(args=['prepped_data' + str((iteration-1)%2) + '.txt', '--no-strict-protocol', \"--endnode\", end_node])\n",
    "        with mr_job.make_runner() as runner: \n",
    "            runner.run()\n",
    "            filename = \"prepped_data\" + str(iteration%2) + \".txt\"\n",
    "            prepped_data = open(filename, 'w')\n",
    "            #no output yet\n",
    "            for line in runner.stream_output():\n",
    "                key, value = mr_job.parse_output_line(line)\n",
    "                print str(key) + \"\\t\" + value\n",
    "                prepped_data.write(str(key) + '\\t' + value + '\\n')\n",
    "            prepped_data.close()\n",
    "            current_counters = runner.counters()\n",
    "            print current_counters\n",
    "            if current_counters[0]['states']['Q'] == 0:\n",
    "                break\n",
    "            if current_counters[0]['completionstatus']['endreached'] != 0:\n",
    "                break\n",
    "            \n",
    "            iteration += 1\n",
    "    print \"Iterations: \" + str(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t[2, 6]|0|[]|Q\n",
      "2\t[1, 3, 4]|9223372036854775807|[]|U\n",
      "3\t[2, 4]|9223372036854775807|[]|U\n",
      "4\t[2, 5]|9223372036854775807|[]|U\n",
      "5\t[1, 2, 4]|9223372036854775807|[]|U\n",
      "\n",
      "\n",
      "Second Job:\n",
      "\n",
      "\n",
      "1\t[2, 6]|0|[1]|V\n",
      "2\t[1, 3, 4]|1|[1]|Q\n",
      "3\t[2, 4]|9223372036854775807|[]|U\n",
      "4\t[2, 5]|9223372036854775807|[]|U\n",
      "5\t[1, 2, 4]|9223372036854775807|[]|U\n",
      "6\t[]|1|[1]|Q\n",
      "[{'states': {'Q': 2}, 'completionstatus': {'endreached': 0}}]\n",
      "1\t[2, 6]|0|[1]|V\n",
      "2\t[1, 3, 4]|1|[1, 2]|V\n",
      "3\t[2, 4]|2|[1, 2]|Q\n",
      "4\t[2, 5]|2|[1, 2]|Q\n",
      "5\t[1, 2, 4]|9223372036854775807|[]|U\n",
      "6\t[]|1|[1, 6]|V\n",
      "[{'states': {'Q': 2}, 'completionstatus': {'endreached': 0}}]\n",
      "1\t[2, 6]|0|[1]|V\n",
      "2\t[1, 3, 4]|1|[1, 2]|V\n",
      "3\t[2, 4]|2|[1, 2, 3]|V\n",
      "4\t[2, 5]|2|[1, 2, 4]|V\n",
      "5\t[1, 2, 4]|3|[1, 2, 4]|Q\n",
      "6\t[]|1|[1, 6]|V\n",
      "[{'states': {'Q': 1}, 'completionstatus': {'endreached': 0}}]\n",
      "1\t[2, 6]|0|[1]|V\n",
      "2\t[1, 3, 4]|1|[1, 2]|V\n",
      "3\t[2, 4]|2|[1, 2, 3]|V\n",
      "4\t[2, 5]|2|[1, 2, 4]|V\n",
      "5\t[1, 2, 4]|3|[1, 2, 4, 5]|V\n",
      "6\t[]|1|[1, 6]|V\n",
      "[{'states': {'Q': 0}, 'completionstatus': {'endreached': 1}}]\n",
      "Iterations: 4\n"
     ]
    }
   ],
   "source": [
    "SSSP(\"directed_toy.txt\",\"1\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Main Dataset 1\n",
    "In the next part of this assignment you will explore a network derived from\n",
    "the NLTK synonym database used for evaluation in HW 5. At a high level, this\n",
    "network is undirected, defined so that there exists link between two nodes/words \n",
    "if the pair or words are a synonym. These data may be found at the location:\n",
    "\n",
    "s3://ucb-mids-mls-networks/synNet/synNet.txt\n",
    "s3://ucb-mids-mls-networks/synNet/indices.txt\n",
    "On under the Data Subfolder for HW7 on Dropbox with the same file names\n",
    "\n",
    "where synNet.txt contains a sparse representation of the network:\n",
    "\n",
    "(index) \\t (dictionary of links)\n",
    "\n",
    "in indexed form, and indices.txt contains a lookup list\n",
    "\n",
    "(word) \\t (index)\n",
    "\n",
    "of indices and words. This network is small enough for you to explore and run\n",
    "scripts locally, but will also be good for a systems test (for later) on AWS.\n",
    "\n",
    "In the dictionary, target nodes are keys, link weights are values \n",
    "(here, all weights are 1, i.e., the network is unweighted).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 7.1\n",
    "\n",
    "Using MRJob, explore the synonyms network data.\n",
    "Consider plotting the degree distribution (does it follow a power law?),\n",
    "and determine some of the key features, like:\n",
    "\n",
    "number of nodes, \n",
    "number links,\n",
    "or the average degree (i.e., the average number of links per node),\n",
    "etc...\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
