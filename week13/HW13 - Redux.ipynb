{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f3c880871d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5781290\n",
      "Time taken: 23.9189379215\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print sc.textFile(\"/data/all-pages-indexed-out.txt\").map(lambda x: 1).reduce(lambda x, y: x + y)\n",
    "print \"Time taken: \" + str(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5781290\n",
      "Time taken: 9.1845138073\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print sc.textFile(\"/data/all-pages-indexed-out.txt\").map(lambda x: 1).reduce(lambda x, y: x + y)\n",
    "print \"Time taken: \" + str(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapCount is for counting the true number of nodes\n",
    "# necessary since nodes with no outgoing links are not listed on their own line\n",
    "\n",
    "def mapCount(entry):\n",
    "    yield (str(entry[0]), 1)\n",
    "    for key, value in entry[1].items():\n",
    "        yield (key, 1)\n",
    "        \n",
    "# processLine turns the string into python objects,\n",
    "# specifically the label and a dictionary of edges.\n",
    "# this assumes zero formatting errors\n",
    "def processLine(line):\n",
    "    splits = line.strip().split('\\t')\n",
    "    return [splits[0], eval(splits[1])]\n",
    "\n",
    "# prep_map generates a line for each possible node, including nodes that exist\n",
    "# only in the edge dictionary of another node\n",
    "def prep_map(entry):\n",
    "    nodeID = entry[0]\n",
    "    edges = entry[1]\n",
    "    for edge, weight in edges.items():\n",
    "        yield (str(edge.strip()), {})\n",
    "    yield (str(nodeID), edges)\n",
    "    \n",
    "# prep_reduce combines the dictionaries of the records created in the map phase\n",
    "def prep_reduce(x, y):\n",
    "    edges = {}\n",
    "    for key, value in x.items():\n",
    "        edges[key] = value\n",
    "    for key, value in y.items():\n",
    "        edges[key] = value\n",
    "    return edges\n",
    "\n",
    "# init_entry distributes the initial probability mass\n",
    "# it also adds a value into the record of 0.0 which will eventually represent\n",
    "# the amount of change in that node's probability mass\n",
    "# which we'll use to check for convergence\n",
    "# it is reliant on the accum_total_pr accumulator for its closure\n",
    "\n",
    "accum_total_pr = sc.accumulator(0.0)\n",
    "\n",
    "def init_entry(entry):\n",
    "    accum_total_pr.add(1.0 / broadcast_nodecount.value)\n",
    "    return (entry[0], [entry[1], 1.0 / broadcast_nodecount.value, 0.0]) #the 0.0 is the delta pr \n",
    "\n",
    "\n",
    "# Phase one consists of a map and reducebykey phase.\n",
    "# phaseOneMapper stores the pr mass of the node as it is as the beginning of the step\n",
    "# if there are no outgoing edges, it passes all the pr mass of that node to the dangling_mass accumulator\n",
    "# which is defined here for the closure.\n",
    "# if there are edges, it divides the pr mass evenly among them and emits the target node with \n",
    "# an empty edge list and a zero previous pr mass.  This is done so that when records are combined\n",
    "# in the reduce step, there will be exactly one record with a full edge list and an accurate\n",
    "# previous pr mass, so we can cummutatively and associatively add the records together\n",
    "# and arrive at a single accurate record\n",
    "\n",
    "accum_dangling_mass = sc.accumulator(0.0)\n",
    "\n",
    "\n",
    "def phaseOneMapper(entry):\n",
    "    label = entry[0]\n",
    "    edges = entry[1][0]\n",
    "    pr = entry[1][1]\n",
    "    previous = pr\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        accum_dangling_mass.add(pr)\n",
    "    else:\n",
    "        forwarding_pr = pr / len(edges)\n",
    "        for edge, weight in edges.items():\n",
    "            yield (edge, [{}, forwarding_pr, 0.0])\n",
    "    yield (label, [edges, 0.0, pr])\n",
    "\n",
    "def phaseOneReducer(x, y):\n",
    "    edges = {}\n",
    "    for edge, weight in x[0].items():\n",
    "        edges[edge] = weight\n",
    "    for edge, weight in y[0].items():\n",
    "        edges[edge] = weight\n",
    "    return [edges, x[1] + y[1], x[2] + y[2]]\n",
    "\n",
    "# the finalize state distributes the dangling pr mass by knowing from the broadcast variables how many\n",
    "# nodes there are and by being passed the dangling mass from a variable defined with the accumulator\n",
    "# in the driver program logic.  It also calculates the final pr mass of the node by the pagerank equation\n",
    "# additionally, it records the absolute value of how much the pr mass of this node has changed and\n",
    "# passes it to the accum_moved_mass accumulator.  \n",
    "# Since the original pr mass value is no longer needed, it is not stored\n",
    "# (recall that it is regenerated in the phase one map step and is simply the value here called pr_prime)\n",
    "\n",
    "accum_moved_mass = sc.accumulator(0.0)\n",
    "\n",
    "def finalize(entry, dangling_mass):\n",
    "    label = str(entry[0])\n",
    "    edges = entry[1][0]\n",
    "    pr = entry[1][1]\n",
    "    previous = entry[1][2]\n",
    "    \n",
    "    pr_prime = broadcast_damping_factor.value * (1.0 / broadcast_nodecount.value) + \\\n",
    "    (1 - broadcast_damping_factor.value) * (dangling_mass / broadcast_nodecount.value + pr)\n",
    "    \n",
    "    accum_moved_mass.add(((pr_prime - previous)**2)**.5)\n",
    "    \n",
    "    return (label, [edges, pr_prime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    if seconds < 60:\n",
    "        return str(seconds) + ' s'\n",
    "    elif seconds < 60*60:\n",
    "        return str(seconds/60) + ' m'\n",
    "    return str(seconds/60/60) + ' h'\n",
    "\n",
    "#using the book's technique\n",
    "def PageRank(filename, repartition = True, verbose = False, iterations = 10):\n",
    "\n",
    "    verbose = False\n",
    "\n",
    "    #load the data and process it\n",
    "#     data = sc.textFile(\"/data/all-pages-indexed-out.txt\").map(processLine).repartition(50).cache()\n",
    "    # data = sc.textFile(\"/data/PageRank-test.txt\").map(processLine)\n",
    "    if repartition:\n",
    "        data = sc.textFile(filename).map(processLine).repartition(25)\n",
    "    else:\n",
    "        data = sc.textFile(filename).map(processLine)\n",
    "\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    # count the true number of nodes\n",
    "    print \"Starting to do smart count\"\n",
    "    start_time = time.time()\n",
    "    nodecount = data.flatMap(mapCount).reduceByKey(lambda x, y: 1).count()\n",
    "    nodecount_time = time.time() - start_time\n",
    "    broadcast_nodecount = sc.broadcast(nodecount)\n",
    "\n",
    "    print \"There are \" + str(broadcast_nodecount.value) + \" nodes in the dataset\"\n",
    "    print \"(\" + format_time(nodecount_time) + \")\\n\"\n",
    "\n",
    "    \n",
    "    broadcast_damping_factor = sc.broadcast(.15)\n",
    "\n",
    "    # conduct the initial preparations\n",
    "    prepped_data = data.flatMap(prep_map).reduceByKey(prep_reduce).cache()\n",
    "    \n",
    "    ranks = prepped_data.map(lambda x: (x[0], 1.0))\n",
    "    \n",
    "    def distribute(baseTuple):\n",
    "        pageID = baseTuple[0]\n",
    "        values = baseTuple[1]\n",
    "        for link , weight in values[0].items():\n",
    "            yield (link, values[1]/len(values[0]))\n",
    "    \n",
    "    print \"Starting to loop\"\n",
    "    looping_start_time = time.time()\n",
    "    for i in range(iterations):\n",
    "        print \"Starting iteration \" + str(i + 1)\n",
    "        iteration_start_time = time.time()\n",
    "        ranks = prepped_data.join(ranks).flatMap(distribute).reduceByKey(lambda x, y: x + y).mapValues(lambda x: .15 + .85*x)\n",
    "        ranks.count()\n",
    "        iteration_duration = time.time() - iteration_start_time\n",
    "        print \"Iteration \" + str(i + 1) + \" took \" + format_time(iteration_duration)\n",
    "        \n",
    "    looping_duration = time.time() - looping_start_time\n",
    "    print \"Looping took \" + format_time(looping_duration)\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to do smart count\n",
      "There are 15192277 nodes in the dataset\n",
      "(3.76208531857 m)\n",
      "\n",
      "Starting to loop\n",
      "Starting iteration 1\n",
      "Iteration 1 took 11.654529798 m\n",
      "Starting iteration 2\n",
      "Iteration 2 took 6.541360418 m\n",
      "Starting iteration 3\n",
      "Iteration 3 took 3.95402544737 m\n",
      "Starting iteration 4\n",
      "Iteration 4 took 3.48739026785 m\n",
      "Starting iteration 5\n",
      "Iteration 5 took 2.76645898422 m\n",
      "Starting iteration 6\n",
      "Iteration 6 took 3.88560298284 m\n",
      "Starting iteration 7\n",
      "Iteration 7 took 2.77663143476 m\n",
      "Starting iteration 8\n",
      "Iteration 8 took 3.80538539886 m\n",
      "Starting iteration 9\n",
      "Iteration 9 took 3.85229249795 m\n",
      "Starting iteration 10\n",
      "Iteration 10 took 3.96437961658 m\n",
      "Looping took 46.6880789518 m\n",
      "[('5704503', 0.1500232217340775), ('1264900', 0.1500232217340775), ('11557656', 0.1500232217340775), ('691874', 0.1500232217340775), ('1325013', 0.1500232217340775), ('3000006', 0.1500232217340775), ('2916454', 0.1500232217340775), ('7421268', 0.1500232217340775), ('6008884', 0.1500232217340775), ('12514353', 0.1500232217340775), ('3000007', 0.1500232217340775), ('11957544', 0.1500232217340775), ('10791480', 0.1500232217340775), ('9445515', 0.1500232217340775), ('14298567', 0.1500232217340775), ('1325015', 0.1500232217340775), ('11957545', 0.1500232217340775), ('10791481', 0.1500232217340775), ('12514352', 0.1500232217340775), ('1325014', 0.1500232217340775), ('746787', 0.1500232217340775), ('3000001', 0.1500232217340775), ('2916453', 0.1500232217340775), ('12469207', 0.1500232217340775), ('14298565', 0.1500232217340775), ('1325017', 0.1500232217340775), ('746784', 0.1500232217340775), ('12468191', 0.1500232217340775), ('13210046', 0.1500232217340775), ('10597784', 0.1500232217340775), ('12468190', 0.1500232217340775), ('1039684', 0.1500232217340775), ('1040454', 0.1500232217340775), ('1325016', 0.1500232217340775), ('3000003', 0.1500232217340775), ('13200419', 0.1500232217340775), ('8004881', 0.1500232217340775), ('4892278', 0.1500232217340775), ('10638148', 0.1500232217340775), ('4056306', 0.1500232217340775), ('11578006', 0.1500232217340775), ('10597780', 0.1500232217340775), ('9839396', 0.1500232217340775), ('7421260', 0.1500232217340775), ('1040450', 0.1500232217340775), ('13200415', 0.1500232217340775), ('1039666', 0.1500232217340775), ('10032329', 0.1500232217340775), ('10958753', 0.1500232217340775), ('7665543', 0.1500232217340775), ('13602089', 0.1500232217340775), ('7582860', 0.1500232217340775), ('2641857', 0.1500232217340775), ('11578005', 0.1500232217340775), ('1039667', 0.1500232217340775), ('7421262', 0.1500232217340775), ('10958752', 0.1500232217340775), ('10217486', 0.1500232217340775), ('2641856', 0.1500232217340775), ('2876377', 0.1500232217340775), ('9839392', 0.1500232217340775), ('2641855', 0.1500232217340775), ('10954162', 0.1500232217340775), ('9839393', 0.1500232217340775), ('11557665', 0.1500232217340775), ('10638141', 0.1500232217340775), ('8005202', 0.1500232217340775), ('2641854', 0.1500232217340775), ('7582857', 0.1500232217340775), ('2641853', 0.1500232217340775), ('2476346', 0.1500232217340775), ('10958756', 0.1500232217340775), ('1297931', 0.1500232217340775), ('1281286', 0.1500232217340775), ('8005200', 0.1500232217340775), ('1040459', 0.1500232217340775), ('4320698', 0.1500232217340775), ('746788', 0.1500232217340775), ('13602087', 0.1500232217340775), ('14298568', 0.1500232217340775), ('8005201', 0.1500232217340775), ('2641851', 0.1500232217340775), ('10377872', 0.1500232217340775), ('2876378', 0.1500232217340775), ('5622704', 0.1500232217340775), ('13495014', 0.1500232217340775), ('2641850', 0.1500232217340775), ('10638145', 0.1500232217340775), ('2876379', 0.1500232217340775), ('750188', 0.1500232217340775), ('3257260', 0.1500232217340775), ('11136108', 0.1500232217340775), ('10413531', 0.1500232217340775), ('3147406', 0.1500232217340775), ('3321842', 0.1500232217340775), ('3184352', 0.1500232217340775), ('3147404', 0.1500232217340775), ('9839398', 0.1500232217340775), ('3184351', 0.1500232217340775), ('3723389', 0.1500232217340775)]\n"
     ]
    }
   ],
   "source": [
    "results = PageRank(\"/data/all-pages-indexed-out.txt\")\n",
    "results_ten_iters = results.takeOrdered(100, key = lambda x: x[1])\n",
    "print results_ten_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to do smart count\n",
      "There are 15192277 nodes in the dataset\n",
      "(4.67370796601 m)\n",
      "\n",
      "Starting to loop\n",
      "Starting iteration 1\n",
      "Iteration 1 took 12.275657316 m\n",
      "Starting iteration 2\n",
      "Iteration 2 took 6.28960686525 m\n",
      "Starting iteration 3\n",
      "Iteration 3 took 3.00849026839 m\n",
      "Starting iteration 4\n",
      "Iteration 4 took 3.05301026901 m\n",
      "Starting iteration 5\n",
      "Iteration 5 took 4.17882626851 m\n",
      "Starting iteration 6\n",
      "Iteration 6 took 4.51280301412 m\n",
      "Starting iteration 7\n",
      "Iteration 7 took 3.49115706682 m\n",
      "Starting iteration 8\n",
      "Iteration 8 took 3.89099051555 m\n",
      "Starting iteration 9\n",
      "Iteration 9 took 3.50828171571 m\n",
      "Starting iteration 10\n",
      "Iteration 10 took 3.81977144877 m\n",
      "Starting iteration 11\n",
      "Iteration 11 took 3.90983154774 m\n",
      "Starting iteration 12\n",
      "Iteration 12 took 4.28215403159 m\n",
      "Starting iteration 13\n",
      "Iteration 13 took 4.00243403514 m\n",
      "Starting iteration 14\n",
      "Iteration 14 took 3.07960991462 m\n",
      "Starting iteration 15\n",
      "Iteration 15 took 4.80930335124 m\n",
      "Starting iteration 16\n",
      "Iteration 16 took 4.42335749865 m\n",
      "Starting iteration 17\n",
      "Iteration 17 took 3.52215046883 m\n",
      "Starting iteration 18\n",
      "Iteration 18 took 4.20555328131 m\n",
      "Starting iteration 19\n",
      "Iteration 19 took 5.04514584939 m\n",
      "Starting iteration 20\n",
      "Iteration 20 took 3.82840981881 m\n",
      "Starting iteration 21\n",
      "Iteration 21 took 4.47072223425 m\n",
      "Starting iteration 22\n",
      "Iteration 22 took 4.46685423056 m\n",
      "Starting iteration 23\n",
      "Iteration 23 took 3.5886127313 m\n",
      "Starting iteration 24\n",
      "Iteration 24 took 4.94620409807 m\n",
      "Starting iteration 25\n",
      "Iteration 25 took 3.75786064863 m\n",
      "Starting iteration 26\n",
      "Iteration 26 took 5.05030360222 m\n",
      "Starting iteration 27\n",
      "Iteration 27 took 3.72694586515 m\n",
      "Starting iteration 28\n",
      "Iteration 28 took 4.68914599816 m\n",
      "Starting iteration 29\n",
      "Iteration 29 took 3.91026410262 m\n",
      "Starting iteration 30\n",
      "Iteration 30 took 5.07099485 m\n",
      "Starting iteration 31\n",
      "Iteration 31 took 5.46783585151 m\n",
      "Starting iteration 32\n",
      "Iteration 32 took 4.18351181746 m\n",
      "Starting iteration 33\n",
      "Iteration 33 took 5.26468436718 m\n",
      "Starting iteration 34\n",
      "Iteration 34 took 4.39031093121 m\n",
      "Starting iteration 35\n",
      "Iteration 35 took 3.78442800045 m\n",
      "Starting iteration 36\n",
      "Iteration 36 took 4.98672628403 m\n",
      "Starting iteration 37\n",
      "Iteration 37 took 3.76809788545 m\n",
      "Starting iteration 38\n",
      "Iteration 38 took 4.93064093192 m\n",
      "Starting iteration 39\n",
      "Iteration 39 took 3.37004781564 m\n",
      "Starting iteration 40\n",
      "Iteration 40 took 4.54052301645 m\n",
      "Starting iteration 41\n",
      "Iteration 41 took 4.62795181672 m\n",
      "Starting iteration 42\n",
      "Iteration 42 took 3.43891594807 m\n",
      "Starting iteration 43\n",
      "Iteration 43 took 5.23202778498 m\n",
      "Starting iteration 44\n",
      "Iteration 44 took 3.72928789854 m\n",
      "Starting iteration 45\n",
      "Iteration 45 took 5.23584716717 m\n",
      "Starting iteration 46\n",
      "Iteration 46 took 3.75229935249 m\n",
      "Starting iteration 47\n",
      "Iteration 47 took 4.96023438374 m\n",
      "Starting iteration 48\n",
      "Iteration 48 took 3.90196168423 m\n",
      "Starting iteration 49\n",
      "Iteration 49 took 5.26069901784 m\n",
      "Starting iteration 50\n",
      "Iteration 50 took 3.91970719894 m\n",
      "Looping took 3.6926717786 h\n",
      "[('1242673', 0.15002322027164527), ('1242672', 0.15002322027164527), ('10283216', 0.15002322027164527), ('2245396', 0.15002322027164527), ('687572', 0.15002322027164527), ('10587391', 0.15002322027164527), ('5619978', 0.15002322027164527), ('10587392', 0.15002322027164527), ('9839396', 0.15002322027164527), ('9839392', 0.15002322027164527), ('9839393', 0.15002322027164527), ('12316148', 0.15002322027164527), ('5927514', 0.15002322027164527), ('12316149', 0.15002322027164527), ('5927515', 0.15002322027164527), ('5927517', 0.15002322027164527), ('5927510', 0.15002322027164527), ('5927511', 0.15002322027164527), ('5927512', 0.15002322027164527), ('9839398', 0.15002322027164527), ('5927513', 0.15002322027164527), ('1308348', 0.15002322027164527), ('9136300', 0.15002322027164527), ('1308349', 0.15002322027164527), ('10278344', 0.15002322027164527), ('5927518', 0.15002322027164527), ('12320132', 0.15002322027164527), ('13210046', 0.15002322027164527), ('3700556', 0.15002322027164527), ('5381464', 0.15002322027164527), ('968478', 0.15002322027164527), ('3700554', 0.15002322027164527), ('3886521', 0.15002322027164527), ('1308344', 0.15002322027164527), ('9644616', 0.15002322027164527), ('8614607', 0.15002322027164527), ('8614604', 0.15002322027164527), ('9802857', 0.15002322027164527), ('12101652', 0.15002322027164527), ('8756192', 0.15002322027164527), ('10254553', 0.15002322027164527), ('1660620', 0.15002322027164527), ('5459229', 0.15002322027164527), ('10587707', 0.15002322027164527), ('3000006', 0.15002322027164527), ('11957544', 0.15002322027164527), ('3000007', 0.15002322027164527), ('11957545', 0.15002322027164527), ('8614608', 0.15002322027164527), ('3000001', 0.15002322027164527), ('9864558', 0.15002322027164527), ('8614609', 0.15002322027164527), ('10775995', 0.15002322027164527), ('3293465', 0.15002322027164527), ('10587701', 0.15002322027164527), ('3000003', 0.15002322027164527), ('13602089', 0.15002322027164527), ('9802918', 0.15002322027164527), ('2246489', 0.15002322027164527), ('9864557', 0.15002322027164527), ('9839379', 0.15002322027164527), ('5328215', 0.15002322027164527), ('2875260', 0.15002322027164527), ('1297931', 0.15002322027164527), ('9864555', 0.15002322027164527), ('13602087', 0.15002322027164527), ('3007152', 0.15002322027164527), ('3007150', 0.15002322027164527), ('3212996', 0.15002322027164527), ('8756241', 0.15002322027164527), ('3007156', 0.15002322027164527), ('9839371', 0.15002322027164527), ('9839373', 0.15002322027164527), ('9839374', 0.15002322027164527), ('2392055', 0.15002322027164527), ('10395594', 0.15002322027164527), ('12676564', 0.15002322027164527), ('10217510', 0.15002322027164527), ('8365669', 0.15002322027164527), ('12316112', 0.15002322027164527), ('9662026', 0.15002322027164527), ('11514460', 0.15002322027164527), ('10587981', 0.15002322027164527), ('8365667', 0.15002322027164527), ('11577353', 0.15002322027164527), ('8365666', 0.15002322027164527), ('7576486', 0.15002322027164527), ('11577352', 0.15002322027164527), ('10587983', 0.15002322027164527), ('1308332', 0.15002322027164527), ('7576487', 0.15002322027164527), ('10587984', 0.15002322027164527), ('11577350', 0.15002322027164527), ('7664365', 0.15002322027164527), ('3268248', 0.15002322027164527), ('2434542', 0.15002322027164527), ('11577355', 0.15002322027164527), ('7582969', 0.15002322027164527), ('11577354', 0.15002322027164527), ('1308338', 0.15002322027164527)]\n"
     ]
    }
   ],
   "source": [
    "results_50_iters = PageRank(\"/data/all-pages-indexed-out.txt\", iterations = 50)\n",
    "print results_50_iters.takeOrdered(100, key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
